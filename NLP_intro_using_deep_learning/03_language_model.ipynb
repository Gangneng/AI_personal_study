{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNy6SK+p+iwdjuYfzbW9fAs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 언어 모델(Language Model)\n","\n","**단어 시퀀스에 확률을 할당(assign)하는 모델**\n","- 이전 단어들이 주어졌을 때 다음으로 올 단어에 확률 할당\n","- 양쪽 단어들로부터 가운데 비어있는 단어에 확률 할당"],"metadata":{"id":"dAdeHsbkwzD_"}},{"cell_type":"markdown","source":["## 언어 모델링(Language Modeling)\n","\n","- 주어진 단어들로부터 모르는 단어를 예측하는 일. "],"metadata":{"id":"PWNzxI2Fxa3_"}},{"cell_type":"markdown","source":["## 단어 시퀀스의 확률 할당\n","1. 기계 번역(Machine Translation)\n"," - P(나는 버스를 **탔다**) > P(나는 버스를 **태운다**)\n","2. 오타 교정(Spell Correction)\n"," - 선생님이 교실로 부리나케 P(**달려갔다**) > P(**잘려갔다**)\n","3. 음성 인식(Speech Recognition)\n"," - P(나는 **메론**을 먹는다) > P(나는 **메롱**을 먹는다)\n","\n","위처럼 언어 모델은 확률을 통해 보다 적절한 문장을 판단."],"metadata":{"id":"zugSp97Gxjtw"}},{"cell_type":"markdown","source":["## 주어진 이전 단어들로부터 다음 단어 예측하기\n","\n","1. 단어 시퀀스 확률\n","$$P(W) = P(w_1, w_2 w_3, w_4, w_5, ..., w_n)$$\n","2. 다음 단어 등장 확률\n","$$P(w_n|w_1, ..., w_{n-1})$$\n","여기서 `|`는 조건부 확률(conditional probability).\n"],"metadata":{"id":"Hf006jmqyefi"}},{"cell_type":"markdown","source":["전체 단어 시퀀스 W의 확률은 모든 단어가 예측된 후 알 수 있으므로 단어 시퀀스 확률은 다음과 같다.\n","$$P(W) = P(w_1, w_2, w_3, w_4, w_5, ..., w_n) = \\prod^{n}_{i=1}P(w_i|w_1, ..., w_{i-1})$$\n","\n","위와 같은 다음 단어 확률을 예측하는 모델은 구글과 같은 검색 엔진에서 유용히 사용되고 있다."],"metadata":{"id":"jXUiRKNEy0xt"}},{"cell_type":"markdown","source":["# 통계적 언어 모델(SLM, Statistical Language Model)"],"metadata":{"id":"fQoIW2myyfsY"}},{"cell_type":"markdown","source":["## 조건부 확률\n","\n","$$p(B|A) = P(A, B)/P(A)$$\n","$$P(A, B) = P(A)P(B|A)$$\n","\n","조건부 확률 연쇄 법칙(chain rule)\n","$$P(A, B, C, D) = P(A)P(B|A)P(C|A,B)P(D|A,B,C)$$\n","$$P(x_1, x_2, x_3, ..., x_n) = P(x_1)P(x_2|x_1)P(x_3|x_1, x_2)...P(x_n|x_1, ... x_{n-1})$$"],"metadata":{"id":"ympNgOIJzpTH"}},{"cell_type":"markdown","source":["### 조건부 확률 이해에 좋은 예제\n"],"metadata":{"id":"qeGQxX_FvoAr"}},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.DataFrame({'남학생':[100,80,180],'여학생':[60,120,180], '계':[160,200,360]})\n","df.index = ['중학생','고등학생','합계']\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"-5QnHej8v5GF","executionInfo":{"status":"ok","timestamp":1675771502078,"user_tz":-540,"elapsed":6,"user":{"displayName":"강냉","userId":"15817296221456897780"}},"outputId":"1a7143b5-8799-4a06-a271-8e7bfaa28b70"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      남학생  여학생    계\n","중학생   100   60  160\n","고등학생   80  120  200\n","합계    180  180  360"],"text/html":["\n","  <div id=\"df-93a8ff17-e6fe-46bf-b111-808124a6f7ba\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>남학생</th>\n","      <th>여학생</th>\n","      <th>계</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>중학생</th>\n","      <td>100</td>\n","      <td>60</td>\n","      <td>160</td>\n","    </tr>\n","    <tr>\n","      <th>고등학생</th>\n","      <td>80</td>\n","      <td>120</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>합계</th>\n","      <td>180</td>\n","      <td>180</td>\n","      <td>360</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93a8ff17-e6fe-46bf-b111-808124a6f7ba')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-93a8ff17-e6fe-46bf-b111-808124a6f7ba button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-93a8ff17-e6fe-46bf-b111-808124a6f7ba');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["위와 같은 표에서 확률을 구해보자.\n","<br>A = 학생이 남학생인 사건\n","<br>B = 학생이 여학생인 사건\n","<br>C = 학생이 중학생인 사건\n","<br>D = 학생이 고등학생인 사건\n","\n","1. 학생을 뽑았을 때, 남학생일 확률\n"," - P(남학생일 확률) / P(학생일 확률) = **P(A)** = 180/360 = 0.5\n","2. 학생을 뽑았을 때, 고등학생이면서 남학생일 확률\n"," - P(남학생일 확률 ∩ 고등학생일 확률) / P(학생일 확률) = **P(A∩D)/P(D)** = 80/360 = 0.222...\n","3. 고등학생 중 한 명을 뽑았을 때, 남학생일 확률 --> 조건부 확률.\n"," - 고등학생을 뽑았다(첫 번째 사건)<br>뽑은 고등학생이 남학생이었다.(두 번째 사건)\n"," - P(남학생일 확률 | 고등학생일 확률) = **P(A|D)** = P(남학생일 확률 ∩ 고등학생일 확률) / P(고등학생일 확률) = **P(A∩D)/P(D)** = (80/360) / (200/360) = 80/200 = 0.4"],"metadata":{"id":"-pxXOjkFw-pu"}},{"cell_type":"markdown","source":["### 문장에 대한 조건부 확률\n","\n","P(An adorable little boy is spreading smiles)\n","\n","$$P(An\\,adorable\\,little\\,boy\\,is\\,spreading\\,smiles) = P(An) \\times P(adorable|An) \\times P(little|An\\,adorable) \\times P(boy|An\\,adorable\\,little) \\times P(is|An\\,adorable\\,little\\,boy) \\times P(spreading|An\\,adorable\\,little\\,boy\\,is) \\times P(smiles|An\\,adorable\\,little\\,boy\\,is\\,spreading)$$"],"metadata":{"id":"malo_VvD0I2A"}},{"cell_type":"markdown","source":["### 카운트 기반 접근\n","\n","기계까 An adorable little boy가 100번 등장했는데 <br>그 다음 is가 등장한 경우가 30번이면 $$P(is|An\\,adorable\\,littlge\\,boy)=30(\\%)$$"],"metadata":{"id":"BR7cCTY_69gw"}},{"cell_type":"markdown","source":["#### 한계 - 희소 문제(Sparsity Problem)\n","\n","위처럼 카운트 기반의 모델을 활용하기 위해선 기계가 훈련하는 데이터의 양이 방대해야만 한다.\n","만약 원하는 문장을 얻으려 할 때 갖고 있는 corpus에서 원하는 문장이 나타난 횟수가 0번이라면 확률은 정의되지 않는다.\n","<br>이처럼 충분한 데이터를 관측하지 못해 언어를 모델링하지 못하는 문제를 **희소 문제**라고 한다.\n"],"metadata":{"id":"5dslqSj-7a83"}},{"cell_type":"markdown","source":["# N-gram \n","\n","카운트 기반 통계적 접근을 사용하는 SLM의 일종인 언어 모델이다.\n","<br>그렇지만 앞서 본 언어 모델과는 달리 모든 단어를 고려하는 것이 아닌 n개의 단어를 고려하는 접근 방법을 사용한다."],"metadata":{"id":"_q0httcL73L5"}},{"cell_type":"markdown","source":["$$P(is|An\\,adorable\\,little\\,boy) \\approx P(is|little\\,boy)$$\n","위처럼 An adorable little boy가 나왔을 때 is가 나올 확류을 구하기 위해 앞 단어 중 임의의 개수만 포함해서 확률을 근사하자."],"metadata":{"id":"FJkXcqp58PaV"}},{"cell_type":"markdown","source":["이 때 임의의 개수를 정하기 위한 기준이 **n-gram**이다.\n","여기서 n은 n개의 연속적 단어 나열을 의미한다.\n","\n","* **uni**grams : 1\n","* **bi**grams : 2\n","* **tri**grams : 3\n","* **4**-grams : 4\n","\n","위에서 든 예시의 경우는 n-1에 해당하는 앞의 단어가 2개이니 n=3인 trigrams이다."],"metadata":{"id":"MRKD3OOG85v8"}},{"cell_type":"markdown","source":["## 한계\n","\n","1. 희소 문제(Sparsity Problem) -> 여전히 존재.\n","2. n을 선택하는 것은 trade-off 문제.\n","  - n을 작게 선택하는 것보다는 커질 수록 성능이 올라감. 하지만 그럴수록 희소 문제 발생.\n","  - 최대 5를 넘게 잡아서는 안 된다 권장."],"metadata":{"id":"P2oV9xc89TBo"}},{"cell_type":"markdown","source":["# 한국어에서의 언어 모델\n","\n","한국어는 다음과 같은 이유로 영어보다 언어 모델로 단어 예측하기 훨씬 까다롭다.\n","1. 한국어는 어순이 중요하지 않음.\n"," - 아니 진짜 그게 아니라\n"," - 진짜 아니 그게 아니라\n"," - 그게 아니라 진짜 아니\n"," - 아니 그게 아니라 진짜\n","2. 한국어는 교착어이다.\n"," - 한국어는 조사가 있다. 이 조사로 굉장히 다양한 형태의 단어가 나온다.\n","  - '그녀' -> 그녀를, 그녀가, 그녀의, 그녀와, 그녀로\n","3. 한국어는 띄어쓰기가 제대로 지켜지지 않는다. 띄어쓰기가 이뤄지지 않아도 의미가 전달되기 때문에...\n"," - 이렇게글을써도읽을수있는우리한글\n"],"metadata":{"id":"VX_SlO9Zr8B7"}},{"cell_type":"markdown","source":["# Perplexity, PPL(펄플렉서티)\n","\n","perplexity는 언어 모델의 평가 지표이다.\n","<br>perplexed는 '헷갈리는'이라는 뜻의 영단어이다.\n","<br>그래서 여기서 PPL은 '헷갈리는 정도'로 이해하자고 설명하고 있다.\n","<br>이러한 perplexity는 낮을수록 모델의 성능이 좋다.\n","\n","$$ PPL(W)=P(w_1, w_2, w_3, ..., w_n)^{-\\frac{1}{N}}=\\sqrt[\\leftroot{-2}\\uproot{2}{N}]{\\frac{1}{P(w_1, w_2, w_3, ..., w_N}}$$\n","여기에 체인룰을 적용하면 아래와 같이 된다.\n","\n","$$ PPL(W)=\\sqrt[\\leftroot{-2}\\uproot{2}{N}]{\\frac{1}{P(w_1, w_2, w_3, ..., w_N}}=\\sqrt[\\leftroot{-2}\\uproot{2}{N}]{\\frac{1}{\\prod^N_{i=1}P(w_i|w_1, w_2, ..., w_{i-1})}}$$"],"metadata":{"id":"chTNg-jHscSu"}},{"cell_type":"markdown","source":["## 분기 계수(Branching factor)\n","\n","**선택할 수 있는 가능한 경우의 수.**\n","어떤 언어 모델의 PPL이 10이 나왔다 가정하자. \n","<br>그러면 이 언어 모델이 다음 단어를 예측할 때마다 평균 10개의 단어 중 어떤 것이 정답인지 헷갈려했다고 생각할 수 있다.\n","<br>즉, 이에 대한 분기 계수는 10이라고 할 수 있을 것이다."],"metadata":{"id":"-e0it007ubKO"}}]}